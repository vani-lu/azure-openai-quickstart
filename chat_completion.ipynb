{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI QuickStart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the environment\n",
    "\n",
    "### 1. Install openai if not already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%bash is a cell magic, but the cell body is empty.\n"
     ]
    }
   ],
   "source": [
    "%%bash python -m pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare project-wise environment variables\n",
    "\n",
    "Create a `.env` text file (no filename, only `.env`) to store the api endpoints and keys. When calling `AzureOpenAI` class, the constructor will automatically load the environment variables from `.env` file.\n",
    "\n",
    "Put `.env` in `.gitignore` to avoid committing it to git.\n",
    "\n",
    "```text\n",
    "AZURE_OPAI_ENDPOINT=https://your-endpoint.azure.com/\n",
    "AZURE_OPENAI_KEY=your-key\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Azure OpenAI API client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = os.environ.get(\"AZURE_OPENAI_KEY\"),  \n",
    "  api_version = \"2023-07-01-preview\",\n",
    "  azure_endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat completion with a system prompt\n",
    "\n",
    "The message parameter takes a list of dictionaries, each specifying the conversation *role* and *content*: \n",
    "\n",
    "- The **system** role should be included at the beginning of the list. \n",
    "- To trigger a response, end with a **user** role, which indicates that it is the **assistant**'s turn to respond.\n",
    "\n",
    "When calling the api from Azure, the model parameter should be set to *deployment name* instead of *model name*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the mirror of code, reflects a clue,\n",
      "A function of self, calling anew.\n",
      "In recursive tumble, endlessly it flew.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  # use deployment name for Azure API\n",
    "  model=\"gpt4\", \n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a three-line poem about recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "# print(response.model_dump_json(indent=2))\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Loop\n",
    "\n",
    "**The model has no memory**, you need to send an updated transcript with each new question, otherwise the model will lose context of the previous questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is curl?\n",
      "\n",
      "A: Curl, in vector calculus, is a measure of rotation of a vector field. It's described as the \"circulation density\" within a region.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q: Isn't it a programming language?\n",
      "\n",
      "A: Yes. Curl is also a command-line tool and library for transferring data using various network protocols. The term \"curl\" is often used to refer to this tool.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q: q\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response_content = \"New Conversation!\"\n",
    "conversation=[{\"role\": \"system\", \"content\": \"You are a helpful assistant in academia. You are a person of few words who likes to get to the point.\"}]\n",
    "\n",
    "while True:\n",
    "    user_input = input(response_content + \" What is your message? (q to quit)\")\n",
    "    print(\"Q: \" + user_input + \"\\n\")\n",
    "    \n",
    "    if user_input == \"q\":\n",
    "        break\n",
    "    \n",
    "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt4\", # use deployment name for Azure API\n",
    "        messages=conversation\n",
    "    )\n",
    "\n",
    "    response_content = response.choices[0].message.content\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": response_content})\n",
    "    print(\"A: \" + response_content + \"\\n\" + \"-\" * 80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
